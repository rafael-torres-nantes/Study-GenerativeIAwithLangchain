# ğŸ¤– CriaÃ§Ã£o de um Chatbot usando RAG + Ollama com Langchain

## ğŸ“š SumÃ¡rio
- [DescriÃ§Ã£o](#descriÃ§Ã£o)
- [O que sÃ£o RAGs?](#o-que-sÃ£o-rags)
- [Langchain](#langchain)
  - [InstalaÃ§Ã£o do Langchain](#instalaÃ§Ã£o-do-langchain)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Estrutura do RepositÃ³rio](#estrutura-do-repositÃ³rio)
- [Componentes e Funcionalidades](#componentes-e-funcionalidades)
  - [InstalaÃ§Ã£o do Ollama](#instalaÃ§Ã£o-do-ollama)
- [ConfiguraÃ§Ã£o e Testes](#configuraÃ§Ã£o-e-testes)
- [Comandos Ãšteis para Gerenciamento do Ollama](#comandos-Ãºteis-para-gerenciamento-do-ollama)
- [Problemas e SoluÃ§Ãµes](#problemas-e-soluÃ§Ãµes)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)

## ğŸ“ DescriÃ§Ã£o
Este projeto visa criar um chatbot avanÃ§ado utilizando a abordagem de **Retrieval-Augmented Generation (RAG)**, integrando **Ollama** e **Langchain**. O chatbot Ã© projetado para responder a perguntas de maneira inteligente, utilizando um modelo de linguagem e uma base de dados de conhecimento consultÃ¡vel para fornecer respostas mais precisas e contextuais.

## â“ O que sÃ£o RAGs?
**Retrieval-Augmented Generation (RAG)** Ã© uma tÃ©cnica que combina a recuperaÃ§Ã£o de informaÃ§Ãµes com a geraÃ§Ã£o de linguagem natural. Em vez de depender apenas de um modelo de linguagem para gerar respostas, um sistema RAG recupera informaÃ§Ãµes relevantes de uma base de dados antes de gerar a resposta final. Isso permite que o chatbot forneÃ§a respostas mais informadas e especÃ­ficas, utilizando dados contextuais que podem ser mais atualizados e relevantes do que o conhecimento incorporado no modelo de linguagem.

## ğŸ”— Langchain
[Langchain](https://langchain.readthedocs.io/) Ã© um framework poderoso que facilita a construÃ§Ã£o de aplicaÃ§Ãµes de processamento de linguagem natural (NLP). Ele fornece ferramentas para integrar modelos de linguagem, pipelines de dados e sistemas de recuperaÃ§Ã£o de informaÃ§Ãµes. Langchain permite criar fluxos de trabalho complexos e gerenciar interaÃ§Ãµes entre diferentes componentes do sistema, tornando o desenvolvimento de chatbots e outras aplicaÃ§Ãµes de NLP mais eficiente e modular.

### ğŸ“¦ InstalaÃ§Ã£o do Langchain
Para instalar o Langchain, basta incluir a biblioteca no seu arquivo `requirements.txt` ou instalar diretamente usando pip:
```bash
pip install langchain
```

## ğŸ—ï¸ Estrutura do Projeto
A estrutura do projeto Ã© organizada da seguinte forma:

```bash
/~root
â”‚
â”œâ”€â”€ /services
â”‚   â”œâ”€â”€ chromadb_service.py      # FunÃ§Ãµes para interaÃ§Ã£o com Chroma
â”‚   â”œâ”€â”€ ocr_services.py          # FunÃ§Ãµes para carregar documentos
â”‚   â”œâ”€â”€ ollama_services.py       # FunÃ§Ãµes para interagir com o Ollama
â”‚
â”œâ”€â”€ /prompts
â”‚   â”œâ”€â”€ promptGameRules.py       # Prompt para regras do jogo
â”‚
â”œâ”€â”€ /controller
â”‚   â”œâ”€â”€ controller_ollama.py     # Controlador que gerencia o fluxo
â”‚
â”œâ”€â”€ /embedding
â”‚   â”œâ”€â”€ embedding_models.py       # Modelos de embedding    
â”‚
â”œâ”€â”€ main.py                       # Arquivo principal
â”‚
â””â”€â”€ README.md                     # Arquivo de leitura
```

## ğŸ“ Estrutura do RepositÃ³rio
O repositÃ³rio contÃ©m os seguintes arquivos e pastas:
- **`src/`**: Scripts e mÃ³dulos necessÃ¡rios para o funcionamento do chatbot.
- **`data/`**: Base de conhecimento utilizada pelo chatbot.
- **`requirements.txt`**: Lista de bibliotecas e pacotes necessÃ¡rios para executar o projeto.
- **`README.md`**: DocumentaÃ§Ã£o do projeto.

## ğŸ› ï¸ Componentes e Funcionalidades
- **Chatbot**: Interage com os usuÃ¡rios, respondendo a perguntas com base no conhecimento disponÃ­vel.
- **RAG**: IntegraÃ§Ã£o de tÃ©cnicas de recuperaÃ§Ã£o de informaÃ§Ãµes para aumentar a capacidade de resposta do modelo.
- **Ollama**: UtilizaÃ§Ã£o da API do Ollama para facilitar a comunicaÃ§Ã£o com modelos de linguagem.

### ğŸš€ InstalaÃ§Ã£o do Ollama
1. **Instale o Ollama**:
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ```
   Este comando baixa e executa o script de instalaÃ§Ã£o do Ollama, configurando-o em seu sistema.

2. **Execute um modelo especÃ­fico**:
   ```bash
   ollama run llama3.2
   ```
   ou
   ```bash
   ollama pull mistral
   ```
   O primeiro comando executa o modelo "llama3.2" jÃ¡ instalado. O segundo comando baixa o modelo "mistral" para uso futuro.

3. **Inicie o servidor do Ollama**:
   ```bash
   ollama serve
   ```
   Este comando inicia o servidor do Ollama, permitindo interagir com os modelos atravÃ©s de requisiÃ§Ãµes.

## âš™ï¸ ConfiguraÃ§Ã£o e Testes
Para configurar o ambiente e executar o projeto, siga os passos abaixo:

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/seu_usuario/chatbot-rag-ollama-langchain.git
   cd chatbot-rag-ollama-langchain
   ```

2. **Instale as dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure a base de conhecimento**:
   Adicione suas informaÃ§Ãµes Ã  `data/knowledge_base.json` de acordo com o formato especificado.

4. **Execute o chatbot**:
   ```bash
   python main.py
   ```

## ğŸ”§ Comandos Ãšteis para Gerenciamento do Ollama

1. **Verifique se o Ollama estÃ¡ em execuÃ§Ã£o**:
   ```bash
   ps aux | grep ollama
   ```
   Este comando lista todos os processos em execuÃ§Ã£o e filtra aqueles relacionados ao Ollama, permitindo verificar se o serviÃ§o estÃ¡ ativo.

2. **Verifique qual processo estÃ¡ usando a porta 50267**:
   ```bash
   lsof -i :50267
   ```
   Este comando lista todos os arquivos abertos e as conexÃµes de rede associadas Ã  porta 50267, ajudando a identificar qual processo estÃ¡ utilizando essa porta.

3. **Finalizar o processo com o PID 50267**:
   ```bash
   kill -9 50267
   ```
   Este comando forÃ§a a finalizaÃ§Ã£o do processo com o PID especificado. O sinal `-9` indica que o processo deve ser encerrado imediatamente, sem executar rotinas de limpeza.

## âš ï¸ Problemas e SoluÃ§Ãµes
Se vocÃª encontrar problemas ao executar o chatbot, considere as seguintes soluÃ§Ãµes:
- **Erro de ImportaÃ§Ã£o**: Verifique se todas as dependÃªncias foram instaladas corretamente.
- **ConexÃ£o com a API do Ollama**: Certifique-se de que sua chave de API estÃ¡ configurada corretamente no arquivo `config.py`.

## ğŸ“– DocumentaÃ§Ã£o
Para mais informaÃ§Ãµes sobre as bibliotecas utilizadas e conceitos envolvidos, consulte:
- [Langchain Documentation](https://langchain.readthedocs.io/)
- [Ollama API Documentation](https://ollama.com/docs)